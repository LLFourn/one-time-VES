%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
\section{Preliminaries}

\subsection{Bitcoin}
We assume a fair amount of familiarity with the Bitcoin transaction structure in Section~\ref{semi-scriptless}. A Bitcoin transaction has the following elements:
\begin{itemize}
    \item A set of inputs, each of which refer to a previous output.
    \item For each input, a witness that satisfies the spending constraints specified in the output it references.
    \item For each input, a \emph{relative} time-lock which prevents the transaction from being included in the ledger until enough time has passed since the output it references was included in the ledger.
    \item A set of new outputs, each with a value and spending constraint.
    \item An \emph{absolute} time-lock, which prevents the transaction from being included in the ledger until a specific time.
\end{itemize}
Whenever a transaction is included in the ledger, its outputs are considered ``spent'' and their value is transferred to the new outputs created by the transaction (and a small fee to the miner who included them).

When we refer to a ``layer-2'' protocol we mean any protocol that is composed of messages sent between the participants and transactions sent to the ledger. A scriptless protocol means any protocol where the transactions only use a basic public key spending constraint which can only be satisfied by a signature on the spending transaction under that public key. It's important to note that a scriptless protocol can still use the time-lock constraints (and most do).

\subsection{Notation}

We analyse security asymptotically with our security parameter as $k$.
We assume that the algorithms for each scheme have been generated by some $\textsf{Setup}(1^k)$ algorithm which generates the a concrete instance of the scheme according to $k$.
By $\negl[k]$ we denote any negligible function of $k$ i.e.  $\negl[k] < 1/p(k)$  for all positive polynomials $p(k)$ and all sufficiently large values of $k$.
We say a probability is ``negligible'' if it can be expressed as $\negl[k]$ or overwhelming if it can be expressed as $1 - \negl[k]$.
A polynomial time adversary runs in time that can be upper bounded by some polynomial of $k$. A \emph{probabilistic} algorithm is also implicitly given a long string of random bits in addition to its other arguments. We denote invoking a probabilistic algorithm with $\sample$. If an algorithm is probabilistic and polynomial time we say it is a \emph{PPT} algorithm.

\subsection{The Discrete Logarithm Problem}

The concrete signature schemes we deal with (Schnorr and ECDSA) are based on the discrete logarithm problem (\DLOG). Written multiplicatively, the \DLOG problem is to find $x \in \ZZ_q$ given $(X,g)$ such that $g^x = X$, in a group $\G$ of prime order by $q$. We denote the fixed generator of a $\DLOG$ based scheme by $g$. In reality $(\G,q,g)$ are fixed by the ledger i.e.\ the Secp256k1 elliptic curve group for Bitcoin, but we reason about them as if the they were generated by the $\textsf{Setup}(1^k)$ algorithm relative to $k$. Note that when we describe schemes based on the \DLOG problem, all scalar operations are implicitly done modulo $q$.


\subsection{Signature Schemes}

% \begin{defintion}azs
%   \label{signature_scheme}

%   A signature scheme $\Sigma$ is made up of three algorithms $(\SIGNALG)$:

%   \begin{itemize}
%   \item $\KeyGen \rightsample (\skSign, pkSign)$: A signing key-pair generation algorithm, which randomly generates a secret signing key $\skSign$ and a public verification key $\pkSign$.
%   \item $\Sign(\skSign, m) \rightarrow \sigma$: A possibly probabilistic signing algorithm that when given a message and the secret signing key $\skSign$ returns a signature $\sigma$.
%   \item $\Verify(\pkSign, m, \sigma) \rightarrow \bin$: A deterministic signature verification algorithm that outputs 1 only if the signature $\sigma$ is valid against the public signature verification key $\pkSign$.
%   \end{itemize}

% \end{defintion}

% \begin{defintion}[\EUFCMA] {
%     A signature scheme $(\epsilon \tau, Q_s)$-\EUFCMA secure for all adversaries $\adv$ making
% }

\subsection{Oracle Simulator Substitution}

In this work we use a non-standard proof technique.
Rather than developing new security reductions for our new security game we take an existing reduction and transform it into a reduction for our property.
Our technique is slightly non-black box in that we treat the reduction as a black-box but separate one or more of its \emph{oracle simulators} into black-boxes as well.
This allows us to replace an oracle simualtor with a different simualtor for a different oracle while maintaining both the view of the new set of adversaries and the original reduction.
First we recall the notion of a security game and reductions between with this separation.

A security game defines two machines (or equivalently algorithms), a challenger $\C$ and adversary $\adv$, that sequentially send messages to each other.
If at the end of the game the \emph{transcript} of the messages satisfy a game specific predicate then the adversary is said to have succeeded, otherwise they have failed.
A simple and relevant example is the signature \emph{unforgeability} games where $\C$ sends $\adv$ a public key $X$ and then $\adv$ succeeds if she sends back a valid signature on any message under $X$.

To show the scheme is secure i.e no such efficient $\adv$ exists, we construct another machine $\R$ (a \emph{reduction}) that uses $\adv$ as a \emph{black-box} to solve some hard problem $\hardproblem$, where $\hardproblem$ is another security game that is assumed to be hard to solve.
From the \emph{view} of $\adv$, interacting with $\R$ must be indistinguishable from interacting with the ordinary challenger $\C$.
The existence of $\R$ \emph{reduction} contradicts the existence of an efficient $\adv$ or more concretely allows us to upper bound the success probability and lower bound the running time of any $\adv$ in terms of the assumed difficultly of $\hardproblem$.

A security game may allow the $\adv$ to query a set of oracles.
For example, in the $\EUFCMA$ game the signature forging adversary may request from $\C$ a signature on a certain message towards its end of forging a signature on another message.
In a reduction, $\R$ must simulate the responses to the queries so they are distributed just they would be if they had come from $\C$.
We will call an algorithm a reduction uses to simulate the responses to oracle queries an \emph{oracle simulator}.



\begin{definition}[Security Reduction with Black-Box Oracle Simualtors]
  \label{security-reduction}
  Let $\hardproblem$ and $\ghardproblem$ describe two security games.
  Let $\C$ be the challenger for $\ghardproblem$, let $\adv$ be an adversary against $\hardproblem$ and let $\R$ be an ITM that interacts with $\C$ and $\R$ concurrently by playing the challenger in $\hardproblem$ and the adversary in $\ghardproblem$.
  We say $\R$ is a reduction from $\ghardproblem$ to $\hardproblem$ if its probability of success and execution time in the $\ghardproblem$ security game is a function of the probability success and execution time of $\adv$ in the $\hardproblem$ security game.
  The existence of $\R$ allows us to bound the success of any adversary against $\hardproblem$ by the difficulty of $\ghardproblem$.
  Specifically, we say $\R$ is a reduction from $\ghardproblem$ to $\hardproblem$ if given any $\adv$ that $(\tau, \e, Q_1,...,Q_n)$-solves $\hardproblem$, $\R$ $(\tau', \e', Q_1',\dots,Q_m')$-solves $\ghardproblem$ where $\e \leq \bound_\e(\e', Q_1,\dots,Q_n) $ and $\tau \geq \bound_\tau(\tau, Q_1,\dots,Q_n)$ and $Q_1,\dots,Q_n$ (resp. $Q_1', \dots, Q_m'$) are the number of queries made by $\adv$ (resp. $\R$) to each of the $n$ (resp. $m$) oracles available while solving $\hardproblem$ (resp. $\ghardproblem$).

  \textbf{oracle queries.} When $\adv$ makes any query to an oracle $\O_i$ it has access to in $\hardproblem$ $\R$ is activated (as it is the notional challenger).
  In particular, $\R$ is activated with $(\mathit{oracle}, i,\mathbf{q})$ where $\query$ is the query $\adv$ is making to $\O_i$.
  $\R$ must then \emph{blindly} forward $q$ to a oracle simulator subroutine $\Sim_i$ along with its own \emph{advice} $\advice$.
  When activated with $(\advice, q)$ the simulator returns $(\radvice, \rquery)$ to $\R$ where $\radvice$ is the simulator's advice to $\R$ and $\rquery$ is the query response.
  $\R$ then inspects $\radvice$ and decides whether to abort but cannot inspect $\rquery$.
  If it does not abort, it outputs the query response $\rquery$ to $\adv$.
  Note that restricting $\R$ so that it cannot read $(\query, \rquery)$ for each query is without loss of generality since, if need be, $\R$ can be defined with a simulator that returns $(\query,\rquery)$ in $\radvice$.

  \textbf{oracle simulator requirements.} $\R$ may be defined with any set of simulators $\Sim_1,\dots,\Sim_n$ for each oracle in $\hardproblem$ as long as they preserve the view $\adv$ with respect to $\hardproblem$.
  $\R$ cannot choose the random tape of its simulators, instead they are provided directly by the environment.
  If $\ghardproblem$ allows oracle queries then the simulators query $\ghardproblem$ directly without activating $\R$.
  The execution time of the simulator contributes to the execution time of $\R$ but the execution of oracles from $\ghardproblem$ do not.

  \textbf{rewinding.} $\R$ may ``rewind'' $\adv$, which in our definition simply means activating a new instance of $\adv$ with the same random tape.
  Despite $\R$ not being able to read query response from the oracle simulators, it may store them and repeat the response for each corresponding query.
  Note it need not inspect the query to do this since after rewinding, the adversary will make the same queries in the same order.
\end{definition}


In our definition we have defined oracle simulators in an unusually discrete way.
Typically, when describing a simulator for an oracle in a reduction researchers will describe the simualtor as part of $\R$ itself.
The simulator will often mutate the internal state of the algorithm and abort on its own accord under certain conditions.
We require that reductions use oracle simulators in a black-box way.
In other words, the oracle simulators are separate functions that can be invoked by the reduction but whose code remains hidden from the reduction.
We do this so we may replace one oracle simulator with another without affecting the reduction.


\begin{lemma}[Simulator Substitution]
  \label{oracle-sub}
  Let $\hardproblem^A$ (resp. $\hardproblem^B$) be a variation of some hard problem $\hardproblem$ where the adversary has access to an additional oracle $A$ (resp. $B$).
  Let $\R$ be a security reduction from $\ghardproblem$ to $\hardproblem^A$ which uses an oracle simulator $\Sim_A$ running in at least $t^A_{\min}$ time per query to simulate $A$.
  Let $\Sim_B$ be a simulator for $B$ running in at most $t^B_{\max}$ time per query.
  If for any $q^B$ there exists a $q^A$ such that the distributions of $\radvice_A$ and $\radvice_B$ are identical for all possible advice $\advice$ where $(\radvice_A, \cdot) \sample \Sim_A(\advice, q^A)$ and $(\radvice_B, \cdot) \sample \Sim_B(\advice, q^B)$,
  then $\R$ is also a reduction from $\ghardproblem$ to $\hardproblem^B$.
  In particular the reduction has bounding functions $(\bound_\e, \bound^B_\tau)$ where $\bound^B_\tau(\tau) = \bound_\tau(\tau) - e(t^B_{\max} - t^A_{\min})$ where $e$ is the number of times $\R^A$ executes $\Sim_A$ (which is the same as the number of times $R^B$ executes $\Sim_B$).
\end{lemma}

\begin{proof}
  Let $\R_A$ and $\R_B$ be instances of a the reduction algorithm with oracle simulators $\Sim_A$ and $\Sim_B$ respectively.
  By definition, given an adversary $\adv_A$ that breaks $\hardproblem^A$ with advantage $\e$, $\R_A$ outputs a solution to $\ghardproblem$ with at probability $\e_A'$ where $\bound_\e(\e_A') \geq \e_A$.
  R must does this regardless of the time that $\adv_A$ takes to run.
  Now consider an adversary $\adv_B$ who breaks $\hardproblem^B$ with advantage $\e$ but $\R_B$ only outputs a solution to $\ghardproblem$ with probability $\e_B'$ where $\e_B' \neq \e_A'$.

  Now we contradict the existence of $\adv_B$,
  Construct an inefficient adversary $\adv_A^*$ against $\hardproblem^A$ using $\adv_B$ as a black box as follows.
  $\adv_A^*$ forwards messages between challenger and $\adv_B$ unmodified.
  Any oracle query $q^B$ made by $\adv_B$ to $B$ $\adv_A^*$ answers by exhaustive search such that the response is distributed identically to the real $B$.
  Additionally, for each query $q^B$, $\adv_A^*$ determines the corresponding query $q^A$ for $q^B$ (as described in the lemma) and queries this to $A$.
  The view of $\R^A$ or $R^B$ at the end of its execution with either adversary will be in the form $(\varGamma, (\advice_1,\radvice_1), \dots, (\advice_e,\radvice_e))$
  where $\varGamma$ is the transcript messages of $\hardproblem$ and $(\advice_i,\radvice_i)$ are the advice given to and received from the oracle simulator for each of the adversary's oracle queries.
  Every $\varGamma$ has equal probability of being from an execution with $\adv_B$ or $\adv_A^*$ since $\adv_A^*$ is just forwarding messages to $\adv_B$.
  This claim extends to the advice $(\advice_1,\radvice_1), \dots, (\advice_e,\radvice_e)$ since each query from $\adv_B$ to $B$ is intercepted by $\adv_A^*$ and converted to the corresponding to query to $A$ which produces an identically distributed $\radvice$ from $\Sim_A$ (the existence of such a query is required by the lemma).
  Since the advantage of $\R^A$ against $\ghardproblem$ when interacting with $\adv_A^*$ is $\e_A'$, the advantage of $\R^B$ interacting with $\adv_B$ must be the same since their views are identical at the end of the execution.
  Therefore the advantage bounds $\R_A$ and $\R_B$ place on the advantage on $\adv_A$ and $\adv_B$ are the same.

  Clearly, the lower bound on the execution of any $\adv_B$ implied by $\R_B$ will the same as $\R_A$ except for losing some factor in the number of oracle simulator executions $e$ multiplied by the upper bound on the overhead of $\Sim_B$ over $\Sim_A$ i.e. $t^B_{\max} - t^A_{\min}$.
\end{proof}

\begin{corollary}[Simulator Substitution with Extra Oracles]
  If in Lemma~\ref{oracle-sub} $\Sim_B$ requires oracle to some additional oracle $\O^*$ to simulate the view of $\adv_B$, then $\R_B$ will be a reduction to $\ghardproblem^*$ instead where $\ghardproblem^*$ is a variant of $\ghardproblem$ that provides $\O^*$.
\end{corollary}
\begin{proof}
  When $\Sim_B$ invokes $\O^*$ it does so without activating $\R$ so the view of $\R$ is unchanged.
  Thus when $\R$ outputs a solution to $\ghardproblem$ from the view of the challenger it is actually outputting a solution to $\ghardproblem^*$ since its oracle simualtor $\Sim_B$ (without $\R$ knowing) made queries to $O^*$.
\end{proof}
